{"cells":[{"metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"96BA18E5100045B0A2DDDA79703846F1","mdEditEnable":true},"cell_type":"markdown","source":"# 1：反向传播神经网络\n### **by:MLZZY**\n**实验描述：处理手写数字数据集，使用反向传播的前馈神经网络，自动学习神经网络的参数。**"},{"metadata":{"id":"E4079162E2204F35BE48E357FE882BE8","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":true},"cell_type":"markdown","source":"### 1：神经网络"},{"outputs":[],"execution_count":2,"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\nfrom scipy.io import loadmat\n#预处理工具\nfrom sklearn.preprocessing import OneHotEncoder","cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"F59CD997EE614B3BB9494783D1448326","scrolled":false}},{"metadata":{"id":"743E53CFE05E4153A0E3B4EDAAC80182","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"{'__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Sun Oct 16 13:09:09 2011',\n '__version__': '1.0',\n '__globals__': [],\n 'X': array([[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]),\n 'y': array([[10],\n        [10],\n        [10],\n        ...,\n        [ 9],\n        [ 9],\n        [ 9]], dtype=uint8)}"},"execution_count":3}],"source":"data=loadmat('/home/mw/input/andrew_ml_ex45345/ex4data1.mat')\ndata","execution_count":3},{"metadata":{"id":"CA1E9A7EF2CB4182835D737D3ACDE335","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"((5000, 400), (5000, 1))"},"execution_count":4}],"source":"X=data['X']\ny=data['y']\nX.shape,y.shape","execution_count":4},{"metadata":{"id":"98610C7B63A14D6389B314619885D7CA","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"((25, 401), (10, 26))"},"execution_count":5}],"source":"weight=loadmat('/home/mw/input/andrew_ml_ex45345/ex4weights.mat')\ntheta1,theta2=weight['Theta1'],weight['Theta2']\ntheta1.shape,theta2.shape","execution_count":5},{"metadata":{"id":"53A9D7F031604386960347DE7D4F1507","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<Figure size 864x864 with 100 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/53A9D7F031604386960347DE7D4F1507/r0y1rba0rk.png\">"}}],"source":"sample_idx=np.random.choice(np.arange(data['X'].shape[0]),100)\nsample_images=data['X'][sample_idx,:]\nfig,ax_array=plt.subplots(nrows=10,ncols=10,sharex=True,sharey=True,figsize=(12,12))\nfor r in range(10):\n    for c in range(10):\n        ax_array[r,c].matshow(np.array(sample_images[10*r+c].reshape((20,20))).T,cmap=matplotlib.cm.binary)\n        plt.xticks(np.array([]))\n        plt.yticks(np.array([]))","execution_count":6},{"metadata":{"id":"0CE318409CDE49828C992443FBE79F18","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def sigmoid(z):\n    return 1/(1+np.exp(-z))","execution_count":7},{"metadata":{"id":"AC5BD5FB8DB644DF8BEBE00438325342","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def forward_propagate(X,theta1,theta2):\n    m=X.shape[0]\n    #常规插入全‘1’列操作\n    a1=np.insert(X,0,values=np.ones(m),axis=1)\n    z2=a1*theta1.T\n    a2=np.insert(sigmoid(z2),0,values=np.ones(m),axis=1)\n    z3=a2*theta2.T\n    h=sigmoid(z3)\n    return a1,z2,a2,z3,h","execution_count":16},{"metadata":{"id":"04FF813524824EFB86736D8F0DDF8007","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":true},"cell_type":"markdown","source":"![Image Name](https://cdn.kesci.com/upload/image/pzgj2aojyc.png?imageView2/0/w/960/h/960)"},{"metadata":{"id":"4081B4C9569E4AAE8837D5CCBA874F91","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"#在不加入正则化项的cost函数中，参数lamda无用，但为了统一，还是加上了\ndef cost(theta1,theta2,input_size,hidden_size,num_labels,X,y,lamda):\n    m=X.shape[0]\n    X=np.matrix(X)\n    y=np.matrix(y)\n    a1,z2,a2,z3,h=forward_propagate(X,theta1,theta2)\n    J=0\n    for i in range(m):\n        first_term=np.multiply(-y[i,:],np.log(h[i,:]))\n        second_term=np.multiply((1-y[i,:]),np.log(1-h[i,:]))\n        J+=np.sum(first_term-second_term)\n    J=J/m\n    return J","execution_count":25},{"metadata":{"id":"5A12E599188A4D858E6B1C2AFD41FA94","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:414: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\nIf you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\nIn case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n  warnings.warn(msg, FutureWarning)\n","name":"stderr"},{"output_type":"execute_result","metadata":{},"data":{"text/plain":"(5000, 10)"},"execution_count":18}],"source":"#y的初始值为5000*1维的向量，下面需要将y编码成5000*10维的矩阵\n#注：此数据集中，手写数字'0'在数据集中用'10'表示，即：\n#y=2，编码后：[0,1,0,0,0,0,0,0,0,0]\n#y=0，编码后：[0,0,0,0,0,0,0,0,0,1]\n#使用Scikitlearn内置的编码函数对y进行编码\n#初始化OneHotEncoder实例时，默认sparse参数为True，编码后返回的是一个稀疏矩阵的对象，如果要使用需要调用toarray()方法将其转化为array对象。\n#若将sparse参数设置为False，则直接生成array对象，可直接使用。\nencoder=OneHotEncoder(sparse=False)\ny_onehot=encoder.fit_transform(y)\ny_onehot.shape","execution_count":18},{"metadata":{"id":"E2CFC586F0D7407987AAC88F64939987","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"(matrix([[10]], dtype=uint8), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]))"},"execution_count":19}],"source":"y[0],y_onehot[0,:]","execution_count":19},{"metadata":{"id":"E95C388544EA4435A5EF59A9727048BD","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"input_size=400\nhidden_size=25\nnum_labels=10\nlamda=1","execution_count":21},{"metadata":{"id":"CF6E750A80C048828355F50963E5D0D7","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"0.2876291651613188"},"execution_count":26}],"source":"cost(theta1,theta2,input_size,hidden_size,num_labels,X,y_onehot,lamda)","execution_count":26},{"metadata":{"id":"1CB23249E056458D870834397B2DB61C","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":true},"cell_type":"markdown","source":"![Image Name](https://cdn.kesci.com/upload/image/pzgju3am60.png?imageView2/0/w/960/h/960)"},{"metadata":{"id":"F8139F0B98164D2281AF6B1E94140497","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"#上面实现了不带正则化项的代价函数，下面实现带正则化项的损失函数\ndef costReg(theta1,theta2,input_size,hidden_size,num_labels,X,y,lamda):\n    m=X.shape[0]\n    X=np.matrix(X)\n    y=np.matrix(y)\n    a1,z2,a2,z3,h=forward_propagate(X,theta1,theta2)\n    J=0\n    for i in range(m):\n        first_term=np.multiply(-y[i,:],np.log(h[i,:]))\n        second_term=np.multiply((1-y[i,:]),np.log(1-h[i,:]))\n        J+=np.sum(first_term-second_term)\n    J=J/m\n    #正则化项\n    J+=(float(lamda)/(2*m))*(np.sum(np.power(theta1[:,1:],2))+np.sum(np.power(theta2[:,1:],2)))\n    return J","execution_count":28},{"metadata":{"id":"36F9F1DD20FD49BC8860DD6CEC4F6F2C","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"0.38376985909092354"},"execution_count":29}],"source":"costReg(theta1,theta2,input_size,hidden_size,num_labels,X,y_onehot,lamda)","execution_count":29},{"metadata":{"id":"87693BA03FC64486B93B6B062C1AF496","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":true},"cell_type":"markdown","source":"### **2：反向传播**\n**实现反向传播的算法，来计算神经网络代价函数的梯度。获得了梯度后，就可以使用工具库函数来计算代价函数的最小值。**"},{"metadata":{"id":"036BD12A80E54E138097AB2791E6A8C6","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"#计算sigmoid函数的梯度\ndef sigmoid_gradient(z):\n    return np.multiply(sigmoid(z),(1-sigmoid(z)))","execution_count":30},{"metadata":{"id":"ED011038584841BFBFF2C81508B63D52","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"0.25"},"execution_count":31}],"source":"sigmoid_gradient(0)","execution_count":31},{"metadata":{"id":"461623407D2E4D188383D7B32EE8FE49","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"#进行随机初始化\n#将theta初始化为[-0.12,0.12]之间的随机值，此范围保证了theta足够小，使学习效率更高\nparams=(np.random.random(size=hidden_size*(input_size+1)+num_labels*(hidden_size+1))-0.5)*0.24","execution_count":32},{"metadata":{"id":"E9C17E1A9AD64F948F8C0CC36D2B557C","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"#反向传播\ndef backprop(params,input_size,hidden_size,num_labels,X,y,lamda):\n    m=X.shape[0]\n    X=np.matrix(X)\n    y=np.matrix(y)\n    #重塑参数形状\n    theta1=np.matrix(np.reshape(params[:hidden_size*(input_size+1)],(hidden_size,(input_size+1))))\n    theta2=np.matrix(np.reshape(params[hidden_size*(input_size+1):],(num_labels,(hidden_size+1))))\n    #前向传播\n    a1,z2,a2,z3,h=forward_propagate(X,theta1,theta2)\n    #初始化\n    J=0\n    delta1=np.zeros(theta1.shape) #(25,401)\n    delta2=np.zeros(theta2.shape) #(10,26)\n    #计算损失函数\n    for i in range(m):\n        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n        J += np.sum(first_term - second_term)\n    J=J/m\n    #执行反向传播\n    for t in range(m):\n        a1t=a1[t,:] #(1,401)\n        z2t=z2[t,:] #(1,25)\n        a2t=a2[t,:] #(1,26)\n        ht=h[t,:] #(1,10)\n        yt=y[t,:] #(1,10)\n        d3t=ht-yt #(1,10)\n        z2t=np.insert(z2t,0,values=np.zeros(1)) #(1,26)\n        d2t=np.multiply((theta2.T*d3t.T).T,sigmoid_gradient(z2t)) #(1,26)\n        delta1=delta1+(d2t[:,1:]).T*a1t\n        delta2=delta2+d3t.T*a2t\n    delta1=delta1/m\n    delta2=delta2/m\n    return J,delta1,delta2","execution_count":37},{"metadata":{"id":"1E9A05D3B45F42548F3530422EFB594A","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"#梯度校验\n#做法见iPad笔记","execution_count":34},{"metadata":{"id":"DA642D0A11B44EF88FFF20D1F53F3603","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"#加入正则化项的反向传播\ndef backpropReg(params,input_size,hidden_size,num_labels,X,y,lamda):\n    m=X.shape[0]\n    X=np.matrix(X)\n    y=np.matrix(y)\n    #重塑参数形状\n    theta1=np.matrix(np.reshape(params[:hidden_size*(input_size+1)],(hidden_size,(input_size+1))))\n    theta2=np.matrix(np.reshape(params[hidden_size*(input_size+1):],(num_labels,(hidden_size+1))))\n    #前向传播\n    a1,z2,a2,z3,h=forward_propagate(X,theta1,theta2)\n    #初始化\n    J=0\n    delta1=np.zeros(theta1.shape) #(25,401)\n    delta2=np.zeros(theta2.shape) #(10,26)\n    #计算损失函数\n    for i in range(m):\n        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n        J += np.sum(first_term - second_term)\n    J=J/m\n    #加入正则化项\n    J+=(float(lamda)/(2*m))*(np.sum(np.power(theta1[:,1:],2))+np.sum(np.power(theta2[:,1:],2)))\n    #执行反向传播\n    for t in range(m):\n        a1t=a1[t,:] #(1,401)\n        z2t=z2[t,:] #(1,25)\n        a2t=a2[t,:] #(1,26)\n        ht=h[t,:] #(1,10)\n        yt=y[t,:] #(1,10)\n        d3t=ht-yt #(1,10)\n        z2t=np.insert(z2t,0,values=np.zeros(1)) #(1,26)\n        d2t=np.multiply((theta2.T*d3t.T).T,sigmoid_gradient(z2t)) #(1,26)\n        delta1=delta1+(d2t[:,1:]).T*a1t\n        delta2=delta2+d3t.T*a2t\n    delta1=delta1/m\n    delta2=delta2/m\n    #加入正则化项\n    delta1[:,1:]=delta1[:,1:]+(theta1[:,1:]*lamda)/m\n    delta2[:,1:]=delta2[:,1:]+(theta2[:,1:]*lamda)/m\n    #将梯度矩阵分解为单个数组\n    grad=np.concatenate((np.ravel(delta1),np.ravel(delta2)))\n    return J,grad","execution_count":38},{"metadata":{"id":"19D2C85A13C04F4280BB9788FF9E0E27","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"     fun: 0.3271794925036686\n     jac: array([ 1.12063780e-04,  7.05355019e-08, -8.21662881e-09, ...,\n       -9.87205862e-05, -4.05536051e-05,  4.23440014e-05])\n message: 'Max. number of function evaluations reached'\n    nfev: 250\n     nit: 21\n  status: 3\n success: False\n       x: array([-1.67722945e+00,  3.52677509e-04, -4.10831441e-05, ...,\n        1.50155377e+00, -4.71339881e-02, -1.99907691e-01])"},"execution_count":43}],"source":"#使用工具库计算参数最优解\nfrom scipy.optimize import minimize\nfmin = minimize(fun=backpropReg, x0=(params), args=(input_size, hidden_size, num_labels, X, y_onehot, lamda), \n                method='TNC', jac=True, options={'maxiter': 250})\nfmin","execution_count":43},{"metadata":{"id":"430594A4EDC34E5EBA4F54BC31A5BB61","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"X = np.matrix(X)\nthetafinal1 = np.matrix(np.reshape(fmin.x[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\nthetafinal2 = np.matrix(np.reshape(fmin.x[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))","execution_count":44},{"metadata":{"id":"A704C45513144BCF8A0182910CE427E8","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"array([[10],\n       [10],\n       [10],\n       ...,\n       [ 9],\n       [ 9],\n       [ 9]])"},"execution_count":45}],"source":"# 使用优化后的θ进行预测\na1, z2, a2, z3, h = forward_propagate(X, thetafinal1, thetafinal2 )\ny_pred = np.array(np.argmax(h, axis=1) + 1)\ny_pred","execution_count":45},{"metadata":{"id":"C6B9B3E02A2D4CCB86F35405AA2478CF","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           1       0.99      0.99      0.99       500\n           2       0.99      0.99      0.99       500\n           3       1.00      0.99      0.99       500\n           4       0.99      0.99      0.99       500\n           5       1.00      1.00      1.00       500\n           6       1.00      1.00      1.00       500\n           7       0.99      0.99      0.99       500\n           8       1.00      1.00      1.00       500\n           9       0.98      0.99      0.99       500\n          10       1.00      1.00      1.00       500\n\n    accuracy                           0.99      5000\n   macro avg       0.99      0.99      0.99      5000\nweighted avg       0.99      0.99      0.99      5000\n\n","name":"stdout"}],"source":"# 预测值与实际值比较\nfrom sklearn.metrics import classification_report\nprint(classification_report(y, y_pred))","execution_count":46},{"metadata":{"id":"BAED7D7F2D83494880FFC38DF2CC1473","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"(25, 400)"},"execution_count":47}],"source":"#可视化隐藏层\nhidden_layer = thetafinal1[:, 1:] \nhidden_layer.shape","execution_count":47},{"metadata":{"id":"88386EC470414D66A9DA400FE956EE85","notebookId":"616785e91e11c300178c065f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<Figure size 864x864 with 25 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/88386EC470414D66A9DA400FE956EE85/r0yanmghwk.png\">"}}],"source":"fig, ax_array = plt.subplots(nrows=5, ncols=5, sharey=True, sharex=True, figsize=(12, 12))\nfor r in range(5):\n    for c in range(5):\n        ax_array[r, c].matshow(np.array(hidden_layer[5 * r + c].reshape((20, 20))),cmap=matplotlib.cm.binary)\n        plt.xticks(np.array([]))\n        plt.yticks(np.array([]))","execution_count":48}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":0}